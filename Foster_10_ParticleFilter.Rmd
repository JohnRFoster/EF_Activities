---
title: "Particle Filter"
author: "John R Foster"
date: "April 18, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(iotools)
library(ecoforecastR)
library(compiler)
par(mfrow=c(1,1))
##` Super Simple Ecosystem Model
##` @param X        [leaf carbon, wood carbon, soil organic carbon] (units=Mg/ha)
##` @param params   model parameters
##` @param inputs   model drivers (air temperature, PAR)
##` @param timestep seconds, defaults to 30 min
SSEM.orig <- function(X,params,inputs,timestep=1800){ 
  
  ne = nrow(X)  ## ne = number of ensemble members
  
  ##Unit Converstion: umol/m2/sec to Mg/ha/timestep
  k = 1e-6*12*1e-6*10000*timestep #mol/umol*gC/mol*Mg/g*m2/ha*sec/timestep
  
  ## photosynthesis
  LAI = X[,1]*params$SLA*0.1  #0.1 is conversion from Mg/ha to kg/m2
  if(inputs$PAR>1e-20){
    GPP = params$alpha*(1-exp(-0.5*LAI))*inputs$PAR
  } else {
    GPP = rep(0,ne)
  }
  
  ## respiration & allocation
  alloc = GPP*params$falloc ## Ra, NPPwood, NPPleaf
  Rh = pmax(params$Rbasal*X[,3]*params$Q10^(inputs$temp/10),X[,3]/k) ## pmax ensures SOM never goes negative
  
  ## turnover
  litter = X[,1]*params$litter
  CWD = X[,2]*params$CWD
  
  ## update states
  X1 = pmax(rnorm(ne,X[,1]+alloc[,3]*k-litter,params$tau.leaf),0)
  X2 = pmax(rnorm(ne,X[,2]+alloc[,2]*k-CWD,params$tau.stem),0)
  X3 = pmax(rnorm(ne,X[,3]+litter+CWD-Rh*k,params$tau.soil),0)
  
  return(cbind(X1=X1,X2=X2,X3=X3,
               LAI=X1*params$SLA*0.1, 
               GPP=GPP,
               NEP=GPP-alloc[,1]-Rh,
               Ra=alloc[,1],NPPw=alloc[,2],NPPl=alloc[,3],
               Rh=Rh,litter=litter,CWD=CWD))
  
}
SSEM <- cmpfun(SSEM.orig)  ## byte compile the function to make it faster

#### SET THE ENSEMBLE SIZE
ne = 1000 ## production run should be 200 - 5000, depending on what your computer can handle

### Initial State (Mg/ha)
Bwood = (c(11983,12097)+c(3668,3799)+c(161,192))*1e-6*10000 ## stem+coarse root + fine root, g/m2->Mg/ha
Bleaf = c(206,236)*0.01
SOM = c(1.57,1.58)+c(0.49,1.39)+c(2.06,2.59)*1e-3*10000
X = as.matrix(c(mean(Bleaf),mean(Bwood),mean(SOM)))
if(ne > 1){
  X = as.matrix(cbind(
    rnorm(ne,X[1],sd(Bleaf)),
    rnorm(ne,X[2],sd(Bwood)),
    rnorm(ne,X[3],sd(SOM))))
}
X.orig = X
pool.lab = c("leaf","wood","SOC")
for(i in 1:3){hist(X[,i],main=pool.lab[i])}

## reimplimentation of the rdirichlet function from MCMCpack
## to fix bug in how it handles alpha as a matrix
rdirichlet.orig = function (n, alpha) 
{
  l <- length(alpha)
  if(is.matrix(alpha)) l <- ncol(alpha)
  x <- matrix(rgamma(l * n, alpha), ncol = l)
  sm <- x %*% rep(1, l)
  return(x/as.vector(sm))
}
rdirichlet <- cmpfun(rdirichlet.orig)         ## byte compile to speed up

## ancillary data from Ameriflux BADM metadata
SLA = 1e3/c(114,120)     ## m2/kg
litter = c(71,94)*0.01*3 ## gC/m2/yr->Mg/ha/yr

### initial params
timestep = 1800 #seconds
params = list()

## univariate priors: expert opinion
params$SLA = rnorm(ne,mean(SLA),sd(SLA))     ## Specific leaf area
params$alpha = rlnorm(ne,log(0.02),0.05)     ## light use efficiency
params$Q10 = rnorm(ne,2.1,0.1)               ## soil respiration Q10
params$Rbasal = rlnorm(ne,log(0.2),1)/(params$Q10^2.5) ## Soil basal respiration (umol/m2/sec per Mg/ha of SOM)

## Process error: expert opinion
params$tau.leaf = 1/sqrt(rgamma(ne,10,10*0.01^2)) ## prior process error in leaf biomass
params$tau.stem = 1/sqrt(rgamma(ne,10,10*0.1^2))  ## prior process error in stem biomass
params$tau.soil = 1/sqrt(rgamma(ne,10,10*0.1^2))  ## prior process error in soil carbon

## multivariate prior on allocation parameters
Ra = 0.5                                     ## assume that NPP is ~50% of GPP on average (Litton et al 2007)
alloc = matrix(c(Ra,(1-0.315)*(1-Ra),0.315*(1-Ra)),1) ## prior mean on allocation, assume leaf NPP is 31.5% of total (Quaife et al 2008)
Neff = matrix(rpois(ne,100),ne)              ## draw effective sample size to add stochasticity to prior
params$falloc = rdirichlet(ne,Neff%*%alloc)  ## prior on [Ra, wood, leaf]

## moment matching beta prior on turnover times
beta.match <- function(mu,var){   ## Beta distribution moment matching
  a = mu*((mu*(1-mu)/var)-1)
  b = a*(1-mu)/mu
  return(data.frame(a=a,b=b))
}
lit = rnorm(10000,mean(litter),sd(litter)/sqrt(2))/      ## simulate litter turnover based on observed litterfall rate and Bleaf prior (initial condition)
  rnorm(10000,mean(Bleaf),sd(Bleaf)/sqrt(2))      
lit.mu = rnorm(ne,mean(lit),sd(lit))*timestep/86400/365  ## draw prior mean and sd; convert turnover per year -> turnover per timestep
lit.sd = 1/sqrt(rgamma(ne,10,10*var(lit)))*timestep/86400/365
CWD.mu = 1/rpois(ne,142)*timestep/86400/365              ## draw prior mean based on background tree mortality rate of 1/142 per year (Dietze et al 2011)
CWD.sd = rbeta(ne,4,4)*CWD.mu*timestep/86400/365         ## draw prior sd assuming a 50% CV
litter.param = beta.match(lit.mu,lit.sd^2)
params$litter = rbeta(ne,litter.param$a,litter.param$b) ## match moments and draw litter prior
CWD.param = beta.match(CWD.mu,CWD.sd^2)
params$CWD = rbeta(ne,CWD.param$a,CWD.param$b)          ## match moments and draw CWD prior
```

## Ensemble

```{r}

## load met data
load("data/Lab10_inputs.RData")
plot(inputs$PAR,type='l')
plot(inputs$temp,type='l')

X = X.orig
nt = nrow(inputs) #17*48     ## production run should be nrow(inputs)   ***********************
output = array(0.0,c(nt,ne,12))         ## output storage 

## foreward ensemble simulation
for(t in 1:nt){
  output[t,,] <- SSEM(X,params,inputs[t,])
  X <- output[t,,1:3]
  #if((t %% 336) == 0) print(t/336)      ## counter: weeks elapsed
}

output[is.nan(output)] = 0
output[is.infinite(output)] = 0

## average the output to daily
bin = 86400/timestep
out.daily = array(0.0,c(ceiling(nt/bin),ne,12))
for(i in 1:12){
  # print(i)
  out.daily[,,i] <- apply(output[,,i],2, ctapply, rep(1:365,each=bin)[1:nt], mean)
}

## Basic time-series visualizations
varnames <- c("Bleaf","Bwood","BSOM","LAI","NEP","GPP","Ra","NPPw","NPPl","Rh","litter","CWD")
units <- c("Mg/ha","Mg/ha","Mg/ha","m2/m2","umol/m2/sec","umol/m2/sec","umol/m2/sec","umol/m2/sec","umol/m2/sec","umol/m2/sec","Mg/ha/timestep","Mg/ha/timestep")
# for(i in 1:12){
#   ci = apply(out.daily[,,i],1,quantile,c(0.025,0.5,0.975))
#   plot(ci[2,],main=varnames[i],xlab="time",ylab=units[i],type='l',ylim=range(ci))
#   ciEnvelope(1:ncol(ci),ci[1,],ci[3,],col=col.alpha("lightGrey",0.5))
#   lines(ci[2,])
# }

## open MODIS data and extract remotely-sensed LAI (LAIr), 
## the standard deviation, and the QAQC flags 
MODIS = read.csv("data/Lat44.45230Lon-121.55740Start2000-01-01End2012-12-31_MOD15A2.asc",
                 header=FALSE,as.is=TRUE,na.string="-3000")
MODvar = substr(MODIS[,1],43,52)
Mtime.raw = substr(MODIS[which(MODvar == "Lai_1km"),3],2,8)
Mtime = as.Date(Mtime.raw,format="%Y%j")
QC = MODIS[which(MODvar == "FparLai_QC"),10]
LAIr = MODIS[which(MODvar == "Lai_1km"),10]*0.1
LAIr.sd = MODIS[which(MODvar == "LaiStdDev_"),10]*0.1

## apply QC
LAIr[QC>1]=NA
LAIr.sd[QC>1]=NA
LAIr.sd[LAIr.sd<0.66]=0.66
plot(Mtime,LAIr,type='l')
plot(LAIr,LAIr.sd)

## select year
yr = grep("2005",Mtime.raw)
LAIr = LAIr[yr]
LAIr.sd = LAIr.sd[yr]
QC = QC[yr]
Mtime = Mtime[yr]

## Calculate model ensemble means for same periods
window = rep(1:(length(yr)),each=48*8,length=nt)
LAIm = t(apply(output[,,4],2,tapply,window,mean))
LAIm.ci  = apply(LAIm,2,quantile,c(0.025,0.5,0.975))

## plot model and observations
Msel = 1:ncol(LAIm.ci)
plot(Mtime[Msel],LAIm.ci[2,],ylab="LAI",xlab="Time",
     ylim=range(c(range(LAIm.ci),range(LAIr,na.rm=TRUE))),type='n')
ciEnvelope(Mtime[Msel],LAIm.ci[1,],LAIm.ci[3,],col=col.alpha("lightGrey",0.5))
points(Mtime,LAIr)    
for(i in 1:length(LAIr)){
  if(!is.na(QC[i])){
    lines(rep(Mtime[i],2),LAIr[i]+c(-1,1)*LAIr.sd[i])
  }
}

for(i in 1:12){
  ci = apply(output[,,i],1,quantile,c(0.025,0.5,0.975))
  plot(ci[2,],main=varnames[i],xlab="time",ylab=units[i],type='l',ylim=range(ci))
  ciEnvelope(1:ncol(ci),ci[1,],ci[3,],col=col.alpha("lightGrey",0.5))
  lines(ci[2,])
}

for(i in 1:3){hist(X[,i],main=pool.lab[i])}
```


## Non-resample

```{r}

## calculate the cumulative likelihoods
## to be used as PF weights
LAIlike = array(NA,dim(LAIm))
sel=1:ncol(LAIm.ci)
for(i in 1:ne){
  LAIlike[i,] = dnorm(LAIm[i,],LAIr[sel],LAIr.sd[sel],log=TRUE)  ## calculate log likelihoods
  LAIlike[i,is.na(LAIlike[i,])] = 0       ## missing data as weight 1; log(1)=0
  LAIlike[i,] = exp(cumsum(LAIlike[i,]))  ## convert to cumulative likelihood
}
hist(LAIlike[,ncol(LAIlike)],main="Final Ensemble Weights")

## Non-resampling Particle Filter
## calculation of CI
nobs = ncol(LAIlike)                     ## number of observations
LAIpf = matrix(NA,3,nobs)
wbar = apply(LAIlike,2,mean)             ## mean weight at each time point
for(i in 1:nobs){
  LAIpf[,i] = wtd.quantile(LAIm[,i],LAIlike[,i]/wbar[i],c(0.025,0.5,0.975))  ## calculate weighted median and CI
}
# hist.params=list()
# sample=0                         ## counter
# for(t in 1:nt){
# 
#   ## forward step
#   output[t,,]=SSEM(X,params,inputs[t,])
#   X=output[t,,1:3]
# 
#   ## analysis step
#   if(t%%(48*8) == 0){            ## if at data frequence (remainder == 0)
#     sample = sample+1            ## increment counter
#    # print(sample)
#     if(!is.na(LAIr[sample])){    ## if observation is present
# 
#       ## calulate Likelihood (weights)
#       Lm = apply(output[t+1-(48*8):1, ,4],2,mean)    ## average model LAI over obs period
#       wt = wbar[sample]   ## calculate likelihood (weight)
# 
#       ## resample
#       index = sample.int(ne,ne,replace=TRUE,prob=wt) ## resample ensemble members in proportion to their weight
#       X = X[index,]                                  ## update state
#       params = update.params(params,index)           ## update parameters
#     }
#     hist.params[[sample+1]] = params                 ## save parameters
#   }
# 
# }

## plot original ensemble and PF with data
col.pf   = c(col.alpha("lightGrey",0.5),col.alpha("lightBlue",0.5),col.alpha("lightGreen",0.5)) ## color sequence
names.pf = c("ensemble","non-resamp PF","resamp PF")                         ## legend names

LAIpr = t(apply(output[,,4],2,tapply,window,mean))         ## summarize PF LAI at measurment frequency
LAIpr.ci  = apply(LAIpr,2,quantile,c(0.025,0.5,0.975))     ## calculate median and CI

par(mfrow=c(1,1))
plot(Mtime[Msel],LAIm.ci[2,],ylim=range(c(range(LAIm.ci),range(LAIr,na.rm=TRUE))),
     type='n',ylab="LAI",xlab="Time")
ciEnvelope(Mtime[Msel],LAIm.ci[1,],LAIm.ci[3,],col=col.pf[1])                ## original ensemble
ciEnvelope(Mtime[Msel],LAIpf[1,],LAIpf[3,],col=col.pf[2])                    ## non-resampling Particle Filter
points(Mtime,LAIr)                                                           ## observations
for(i in 1:length(LAIr)){                                                    ## observation uncertainty
  if(!is.na(QC[i])){
    lines(rep(Mtime[i],2),LAIr[i]+c(-1,1)*LAIr.sd[i])
  }
}
legend("topleft",legend=names.pf[1:2],col=col.pf[1:2],lwd=5)

# for(i in 1:12){
#   ci = apply(output[,,i],1,quantile,c(0.025,0.5,0.975))
#   plot(ci[2,],main=varnames[i],xlab="time",ylab=units[i],type='l',ylim=range(ci))
#   ciEnvelope(1:ncol(ci),ci[1,],ci[3,],col=col.alpha("lightGrey",0.5))
#   lines(ci[2,])
# }

```


## Resample

```{r}

update.params <- function(params,index){
  params$falloc  = params$falloc[index,]
  params$SLA     = params$SLA[index]
  params$alpha   = params$alpha[index]
  params$Q10     = params$Q10[index]
  params$Rbasal  = params$Rbasal[index]
  params$litter  = params$litter[index]
  params$CWD     = params$CWD[index]
  params$tau.leaf  = params$tau.leaf[index]
  params$tau.stem  = params$tau.stem[index]
  params$tau.soil  = params$tau.soil[index]
  return(params)
}

hist.params=list()               ## since we resample parameters, create a record (history) of what values were used at each step
hist.params[[1]] = params        ## initialize with original parameters
X = X.orig                       ## reset state to the initial values, not the final values from the previous ensemble
output.ensemble = output         ## save original projection

### resampling particle filter
sample=0                         ## counter
for(t in 1:nt){
  
  ## forward step
  output[t,,]=SSEM(X,params,inputs[t,])
  X=output[t,,1:3]
  
  ## analysis step
  if(t%%(48*8) == 0){            ## if at data frequence (remainder == 0)
    sample = sample+1            ## increment counter
   # print(sample)
    if(!is.na(LAIr[sample])){    ## if observation is present
      
      ## calulate Likelihood (weights)
      Lm = apply(output[t+1-(48*8):1, ,4],2,mean)    ## average model LAI over obs period
      wt = dnorm(LAIr[sample],Lm,LAIr.sd[sample])    ## calculate likelihood (weight)
      
      ## resample 
      index = sample.int(ne,ne,replace=TRUE,prob=wt) ## resample ensemble members in proportion to their weight
      X = X[index,]                                  ## update state
      params = update.params(params,index)           ## update parameters
    }
    hist.params[[sample+1]] = params                 ## save parameters
  }
  
}

## save all the output
#save(output,output.ensemble,LAIlike,hist.params,inputs,file="Ex10.output.RData") 

## Extract and summarize LAI (pr = PF, resampling)
LAIpr = t(apply(output[,,4],2,tapply,window,mean))         ## summarize PF LAI at measurment frequency
LAIpr.ci  = apply(LAIpr,2,quantile,c(0.025,0.5,0.975))     ## calculate median and CI

## plot time-series
par(mfrow=c(1,1))
plot(Mtime[Msel],LAIm.ci[2,],ylim=range(c(range(LAIm.ci),range(LAIr,na.rm=TRUE))),
     type='n',ylab="LAI",xlab="Time",main="Without Uncertainty")
ciEnvelope(Mtime[Msel],LAIm.ci[1,],LAIm.ci[3,],col=col.pf[1]) 
ciEnvelope(Mtime[Msel],LAIpf[1,],LAIpf[3,],col=col.pf[2])
ciEnvelope(Mtime[Msel],LAIpr.ci[1,],LAIpr.ci[3,],col=col.pf[3])
points(Mtime,LAIr)    
for(i in 1:length(LAIr)){
  if(!is.na(QC[i])){
    lines(rep(Mtime[i],2),LAIr[i]+c(-1,1)*LAIr.sd[i])
  }
}
legend("topleft",legend=names.pf,col=col.pf,lwd=5)

for(i in 1:12){
  ci = apply(output[,,i],1,quantile,c(0.025,0.5,0.975))
  plot(ci[2,],main=varnames[i],xlab="time",ylab=units[i],type='l',ylim=range(ci))
  ciEnvelope(1:ncol(ci),ci[1,],ci[3,],col=col.alpha("lightGrey",0.5))
  lines(ci[2,])
}

pool.lab = c("leaf","wood","SOC")
for(i in 1:3){hist(X[,i],main=pool.lab[i])}

### assess shifts in any parameter values
par(mfrow=c(3,4))
par(mar=c(2,2,4,0.7))
for(i in 1:length(params)){
  if(is.null(dim(params[[i]]))){ ## parameter is scalar
    orig = density(hist.params[[1]][[i]])
    new = density(params[[i]])
    ylim=range(c(range(new$y),range(orig$y)))
    plot(orig,main=names(params)[i],xlab=" ",
         ylim=ylim)
    lines(new,col=2,lwd=2)
    text(max(orig$x),ylim[2],
         paste(format(mean(hist.params[[1]][[i]]),digits=3),
               format(sd(hist.params[[1]][[i]]),digits=3)),
         pos=2)
    text(max(orig$x),ylim[2]*0.9,
         paste(format(mean(params[[i]]),digits=3),
               format(sd(params[[i]]),digits=3)),
         pos=2,col=2)
  } else {
    ## parameter is vector
    for(j in 1:ncol(params[[i]])){
      orig = density(hist.params[[1]][[i]][,j])
      new = density(params[[i]][,j])
      ylim=range(c(range(new$y),range(orig$y)))
      plot(orig,main=paste(names(params)[i],j), xlab=" ",
           ylim=ylim)
      lines(new,col=2,lwd=2)
      text(max(orig$x),ylim[2],
           paste(format(mean(hist.params[[1]][[i]][,j]),digits=3),
                 format(sd(hist.params[[1]][[i]][,j]),digits=3)),
           pos=2)
      text(max(orig$x),ylim[2]*0.9,
           paste(format(mean(params[[i]][,j]),digits=3),
                 format(sd(params[[i]][,j]),digits=3)),
           pos=2,col=2)
    }      
  }  
}

```


```{r}

### Initial State (Mg/ha)
Bwood = (c(11983,12097)+c(3668,3799)+c(161,192))*1e-6*10000 ## stem+coarse root + fine root, g/m2->Mg/ha
Bleaf = c(206,236)*0.01
SOM = c(1.57,1.58)+c(0.49,1.39)+c(2.06,2.59)*1e-3*10000
X = as.matrix(c(mean(Bleaf),mean(Bwood),mean(SOM)))
if(ne > 1){
  X = as.matrix(cbind(
    rnorm(ne,X[1],sd(Bleaf)),
    rnorm(ne,X[2],sd(Bwood)),
    rnorm(ne,X[3],sd(SOM))))
}

### initial params
timestep = 1800 #seconds
params = list()

## univariate priors: expert opinion
params$SLA = rnorm(ne,mean(SLA),sd(SLA))     ## Specific leaf area
params$alpha = rlnorm(ne,log(0.02),0.05)     ## light use efficiency
params$Q10 = rnorm(ne,2.1,0.1)               ## soil respiration Q10
params$Rbasal = rlnorm(ne,log(0.2),1)/(params$Q10^2.5) ## Soil basal respiration (umol/m2/sec per Mg/ha of SOM)

## Process error: expert opinion
params$tau.leaf = 1/sqrt(rgamma(ne,10,10*0.01^2)) ## prior process error in leaf biomass
params$tau.stem = 1/sqrt(rgamma(ne,10,10*0.1^2))  ## prior process error in stem biomass
params$tau.soil = 1/sqrt(rgamma(ne,10,10*0.1^2))  ## prior process error in soil carbon

## multivariate prior on allocation parameters
Ra = 0.5                                     ## assume that NPP is ~50% of GPP on average (Litton et al 2007)
alloc = matrix(c(Ra,(1-0.315)*(1-Ra),0.315*(1-Ra)),1) ## prior mean on allocation, assume leaf NPP is 31.5% of total (Quaife et al 2008)
Neff = matrix(rpois(ne,100),ne)              ## draw effective sample size to add stochasticity to prior
params$falloc = rdirichlet(ne,Neff%*%alloc)  ## prior on [Ra, wood, leaf]

## moment matching beta prior on turnover times
beta.match <- function(mu,var){   ## Beta distribution moment matching
  a = mu*((mu*(1-mu)/var)-1)
  b = a*(1-mu)/mu
  return(data.frame(a=a,b=b))
}
lit = rnorm(10000,mean(litter),sd(litter)/sqrt(2))/      ## simulate litter turnover based on observed litterfall rate and Bleaf prior (initial condition)
  rnorm(10000,mean(Bleaf),sd(Bleaf)/sqrt(2))      
lit.mu = rnorm(ne,mean(lit),sd(lit))*timestep/86400/365  ## draw prior mean and sd; convert turnover per year -> turnover per timestep
lit.sd = 1/sqrt(rgamma(ne,10,10*var(lit)))*timestep/86400/365
CWD.mu = 1/rpois(ne,142)*timestep/86400/365              ## draw prior mean based on background tree mortality rate of 1/142 per year (Dietze et al 2011)
CWD.sd = rbeta(ne,4,4)*CWD.mu*timestep/86400/365         ## draw prior sd assuming a 50% CV
litter.param = beta.match(lit.mu,lit.sd^2)
params$litter = rbeta(ne,litter.param$a,litter.param$b) ## match moments and draw litter prior
CWD.param = beta.match(CWD.mu,CWD.sd^2)
params$CWD = rbeta(ne,CWD.param$a,CWD.param$b)          ## match moments and draw CWD prior

## load met data
load("data/Lab10_inputs.RData")

nt = nrow(inputs) #17*48     ## production run should be nrow(inputs)   ***********************
output = array(0.0,c(nt,ne,12))         ## output storage 


### resampling particle filter without parameter uncertainty
sample=0                         ## counter
for(t in 1:nt){
  
  ## forward step
  output[t,,]=SSEM(X,params,inputs[t,])
  X=output[t,,1:3]
  
  ## analysis step
  if(t%%(48*8) == 0){            ## if at data frequence (remainder == 0)
    sample = sample+1            ## increment counter
   # print(sample)
    if(!is.na(LAIr[sample])){    ## if observation is present
      
      ## calulate Likelihood (weights)
      Lm = apply(output[t+1-(48*8):1, ,4],2,mean)    ## average model LAI over obs period
      wt = dnorm(LAIr[sample],Lm,LAIr.sd[sample])    ## calculate likelihood (weight)
      
      ## resample 
      index = sample.int(ne,ne,replace=TRUE,prob=wt) ## resample ensemble members in proportion to their weight
      X = X[index,]                                  ## update state
     # params = update.params(params,index)           ## update parameters
      
      params$falloc[,1]  = rep(mean(params$falloc[,1]), ne)
      params$falloc[,2]  = rep(mean(params$falloc[,2]), ne)
      params$falloc[,3]  = rep(mean(params$falloc[,3]), ne)
      params$SLA     = rep(mean(params$SLA), ne)
      params$alpha   = rep(mean(params$alpha), ne)
      params$Q10     = rep(mean(params$Q10), ne)
      params$Rbasal  = rep(mean(params$Rbasal), ne)
      params$litter  = rep(mean(params$litter), ne)
      params$CWD     = rep(mean(params$CWD), ne)
      params$tau.leaf  = rep(mean(params$tau.leaf), ne)
      params$tau.stem  = rep(mean(params$tau.stem), ne)
      params$tau.soil  = rep(mean(params$tau.soil), ne)
    }
    hist.params[[sample+1]] = params                 ## save parameters
  }
  
}

## save all the output
#save(output,output.ensemble,LAIlike,hist.params,inputs,file="Ex10.output.RData") 

## Extract and summarize LAI (pr = PF, resampling)
LAIpr = t(apply(output[,,4],2,tapply,window,mean))         ## summarize PF LAI at measurment frequency
LAIpr.ci  = apply(LAIpr,2,quantile,c(0.025,0.5,0.975))     ## calculate median and CI

## plot time-series
par(mfrow=c(1,1))
plot(Mtime[Msel],LAIm.ci[2,],ylim=range(c(range(LAIm.ci),range(LAIr,na.rm=TRUE))),
     type='n',ylab="LAI",xlab="Time",main="Without Uncertainty")
ciEnvelope(Mtime[Msel],LAIm.ci[1,],LAIm.ci[3,],col=col.pf[1]) 
ciEnvelope(Mtime[Msel],LAIpf[1,],LAIpf[3,],col=col.pf[2])
ciEnvelope(Mtime[Msel],LAIpr.ci[1,],LAIpr.ci[3,],col=col.pf[3])
points(Mtime,LAIr)    
for(i in 1:length(LAIr)){
  if(!is.na(QC[i])){
    lines(rep(Mtime[i],2),LAIr[i]+c(-1,1)*LAIr.sd[i])
  }
}
legend("topleft",legend=names.pf,col=col.pf,lwd=5)

for(i in 1:12){
  ci = apply(output[,,i],1,quantile,c(0.025,0.5,0.975))
  plot(ci[2,],main=varnames[i],xlab="time",ylab=units[i],type='l',ylim=range(ci))
  ciEnvelope(1:ncol(ci),ci[1,],ci[3,],col=col.alpha("lightGrey",0.5))
  lines(ci[2,])
}

pool.lab = c("leaf","wood","SOC")
for(i in 1:3){hist(X[,i],main=pool.lab[i])}

### assess shifts in any parameter values
par(mfrow=c(3,4))
par(mar=c(2,2,4,0.7))
for(i in 1:length(params)){
  if(is.null(dim(params[[i]]))){ ## parameter is scalar
    orig = density(hist.params[[1]][[i]])
    new = density(params[[i]])
    ylim=range(c(range(new$y),range(orig$y)))
    plot(orig,main=names(params)[i],xlab=" ",
         ylim=ylim)
    lines(new,col=2,lwd=2)
    text(max(orig$x),ylim[2],
         paste(format(mean(hist.params[[1]][[i]]),digits=3),
               format(sd(hist.params[[1]][[i]]),digits=3)),
         pos=2)
    text(max(orig$x),ylim[2]*0.9,
         paste(format(mean(params[[i]]),digits=3),
               format(sd(params[[i]]),digits=3)),
         pos=2,col=2)
  } else {
    ## parameter is vector
    for(j in 1:ncol(params[[i]])){
      orig = density(hist.params[[1]][[i]][,j])
      new = density(params[[i]][,j])
      ylim=range(c(range(new$y),range(orig$y)))
      plot(orig,main=paste(names(params)[i],j), xlab=" ",
           ylim=ylim)
      lines(new,col=2,lwd=2)
      text(max(orig$x),ylim[2],
           paste(format(mean(hist.params[[1]][[i]][,j]),digits=3),
                 format(sd(hist.params[[1]][[i]][,j]),digits=3)),
           pos=2)
      text(max(orig$x),ylim[2]*0.9,
           paste(format(mean(params[[i]][,j]),digits=3),
                 format(sd(params[[i]][,j]),digits=3)),
           pos=2,col=2)
    }      
  }  
}

```




